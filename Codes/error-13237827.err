┌ Error: CUDA.jl could not find an appropriate CUDA runtime to use.
│ 
│ This can have several reasons:
│ * you are using an unsupported platform: this version of CUDA.jl
│   only supports Linux (x86_64, aarch64, ppc64le) and Windows (x86_64),
│   while your platform was identified as x86_64-linux-gnu-libgfortran5-cxx11-libstdcxx29-cuda+none-julia_version+1.8.1;
│ * you precompiled CUDA.jl in an environment where the CUDA driver
│   was not available (i.e., a container, or an HPC login node).
│   in that case, you need to specify which CUDA version to use
│   by calling `CUDA.set_runtime_version!`;
│ * you requested use of a local CUDA toolkit, but not all
│   required components were discovered. try running with
│   JULIA_DEBUG=all in your environment for more details.
│ 
│ For more details, refer to the CUDA.jl documentation at
│ https://cuda.juliagpu.org/stable/installation/overview/
└ @ CUDA ~/.julia/packages/CUDA/s5N6v/src/initialization.jl:82
┌ Warning: Layer with Float32 parameters got Float64 input.
│   The input will be converted, but any earlier layers may be very slow.
│   layer = Dense(50 => 17, σ)  # 867 parameters
│   summary(x) = "50×16 Matrix{Float64}"
└ @ Flux ~/.julia/packages/Flux/n3cOc/src/layers/stateless.jl:60
[ Info: Epoch: 5 , Loss: 59144.098064704216
[ Info: Epoch: 10 , Loss: 58338.25517694489
[ Info: Epoch: 15 , Loss: 57566.0456810512
[ Info: Epoch: 20 , Loss: 56806.211358203
[ Info: Epoch: 25 , Loss: 56047.05630283544
[ Info: Epoch: 30 , Loss: 55313.18590649718
[ Info: Epoch: 5 , Loss: 59291.838330098006
[ Info: Epoch: 10 , Loss: 58498.691691316504
[ Info: Epoch: 15 , Loss: 57740.16155440936
[ Info: Epoch: 20 , Loss: 56968.50107912591
[ Info: Epoch: 25 , Loss: 56196.250839454115
[ Info: Epoch: 30 , Loss: 55437.80740265721
[ Info: Epoch: 5 , Loss: 58759.091793396816
[ Info: Epoch: 10 , Loss: 57067.548750615955
[ Info: Epoch: 15 , Loss: 55228.20156197706
[ Info: Epoch: 20 , Loss: 53128.37219299907
[ Info: Epoch: 25 , Loss: 50725.839548101496
[ Info: Epoch: 30 , Loss: 48164.24699510673
[ Info: Epoch: 5 , Loss: 58759.091793396816
[ Info: Epoch: 10 , Loss: 57067.548750615955
[ Info: Epoch: 15 , Loss: 55228.20156197706
[ Info: Epoch: 20 , Loss: 53128.37219299907
[ Info: Epoch: 25 , Loss: 50725.839548101496
[ Info: Epoch: 30 , Loss: 48164.24699510673
[ Info: Epoch: 5 , Loss: 59291.838330098006
[ Info: Epoch: 10 , Loss: 58498.691691316504
[ Info: Epoch: 15 , Loss: 57740.16155440936
[ Info: Epoch: 20 , Loss: 56968.50107912591
[ Info: Epoch: 25 , Loss: 56196.250839454115
[ Info: Epoch: 30 , Loss: 55437.80740265721
[ Info: Epoch: 5 , Loss: 59291.838330098006
[ Info: Epoch: 10 , Loss: 58498.691691316504
[ Info: Epoch: 15 , Loss: 57740.16155440936
[ Info: Epoch: 20 , Loss: 56968.50107912591
[ Info: Epoch: 25 , Loss: 56196.250839454115
[ Info: Epoch: 30 , Loss: 55437.80740265721
[ Info: Epoch: 5 , Loss: 58759.091793396816
[ Info: Epoch: 10 , Loss: 57067.548750615955
[ Info: Epoch: 15 , Loss: 55228.20156197706
[ Info: Epoch: 20 , Loss: 53128.37219299907
[ Info: Epoch: 25 , Loss: 50725.839548101496
[ Info: Epoch: 30 , Loss: 48164.24699510673
[ Info: Epoch: 5 , Loss: 58759.091793396816
[ Info: Epoch: 10 , Loss: 57067.548750615955
[ Info: Epoch: 15 , Loss: 55228.20156197706
[ Info: Epoch: 20 , Loss: 53128.37219299907
[ Info: Epoch: 25 , Loss: 50725.839548101496
[ Info: Epoch: 30 , Loss: 48164.24699510673
